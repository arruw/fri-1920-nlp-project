{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lemmagen.lemmatizer\n",
    "from lemmagen.lemmatizer import Lemmatizer\n",
    "\n",
    "lemmatizer = Lemmatizer(dictionary=lemmagen.DICTIONARY_SLOVENE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhood(index, distance):\n",
    "    before = df.word.values[index-distance:index]\n",
    "    after = df.word.values[index+1:index+distance+1]\n",
    "    \n",
    "    return before.tolist() + after.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"SentiCoref_1.0\"\n",
    "files = os.listdir(folder)\n",
    "combined_entities = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(folder + \"/\" + file, \n",
    "                     sep=\"\\t\", \n",
    "                     skiprows=7, \n",
    "                     header=None, \n",
    "                     names=[\"token\", \"char\", \"word\", \"entity\", \"sentiment\", \"occurrence\", \"number\", \"NaN\"], \n",
    "                     quoting=3, \n",
    "                     encoding=\"utf-8\")\n",
    "\n",
    "    names = []\n",
    "    entities = []\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        #check if word is an entity\n",
    "        if df[\"entity\"].values[i] != \"_\" and df[\"occurrence\"].values[i] != df[\"occurrence\"].values[i-1]:\n",
    "            number = df[\"number\"].values[i]\n",
    "            name = file.split(\".\")[0] + \"_\" + number[number.find(\"[\")+1:number.find(\"]\")]\n",
    "            entity = df[\"entity\"].values[i][:3]\n",
    "            neighborhood = get_neighborhood(i, 3)\n",
    "            #check if entity already in list\n",
    "            if name in names:\n",
    "                #add tokens\n",
    "                entities[names.index(name)][\"tokens\"] += neighborhood\n",
    "            else:\n",
    "                #create new entity entry\n",
    "                names.append(name)\n",
    "                entities.append({\"name\": name,\n",
    "                                 \"entity\": entity,\n",
    "                                 \"tokens\": neighborhood,\n",
    "                                 \"sentiment\": -1\n",
    "                })\n",
    "            #add sentiment to entity\n",
    "            if df[\"sentiment\"].values[i] != \"_\":\n",
    "                entities[names.index(name)][\"sentiment\"] = int(df[\"sentiment\"].values[i][0])\n",
    "                \n",
    "    combined_entities += entities\n",
    "    df = pd.DataFrame(combined_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization, punctuation removal, lowercase\n",
    "for i in range(df.shape[0]):\n",
    "    df.tokens[i] = \" \".join([lemmatizer.lemmatize(token).lower() for token in df.tokens[i] if str.isalnum(token)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove negative sentiments which are a result of a bug\n",
    "df = df.loc[df['sentiment'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add two separate classes for binary classification of neutral and polar entities\n",
    "binary_list = []\n",
    "for i in range(df.shape[0]):\n",
    "    tokens = df.tokens.values[i]\n",
    "    entity = df.entity.values[i]\n",
    "    sentiment = df.sentiment.values[i]\n",
    "    if sentiment == 3:\n",
    "        neutral = 1\n",
    "    else:\n",
    "        neutral = 0\n",
    "    if sentiment > 3:\n",
    "        positive = 1\n",
    "    elif sentiment < 3:\n",
    "        positive = 0\n",
    "    else:\n",
    "        positive = -1\n",
    "    data = {\"tokens\":tokens, \"LOC\": 0, \"ORG\": 0, \"PER\": 0, \"sentiment\": sentiment, \"neutral\": neutral, \"positive\": positive}\n",
    "    data[entity] = 1\n",
    "    binary_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(binary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>komisija mora narediti kolega b komisija anali...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>današnji srečanje v povedati minister za</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>po njun beseda in francija podoben podoben usm...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>beseda slovenija in podoben stališče glede usm...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>v čas predsedovanje prihodnji leto med možen u...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ukrep eu jesti omeniti obnova zemlja dogajanje...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>raven tuditi mena da slovenija in francija jes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>stelzero jesti že sin france rosti stelzero že...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>analiza dnk roda naj biti jesti domneven sin r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>on oddati v p poročanje soden medicina v n pa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  LOC  ORG  PER  \\\n",
       "0  komisija mora narediti kolega b komisija anali...    0    1    0   \n",
       "1           današnji srečanje v povedati minister za    1    0    0   \n",
       "2  po njun beseda in francija podoben podoben usm...    0    1    0   \n",
       "3  beseda slovenija in podoben stališče glede usm...    0    1    0   \n",
       "4  v čas predsedovanje prihodnji leto med možen u...    0    1    0   \n",
       "5  ukrep eu jesti omeniti obnova zemlja dogajanje...    0    0    1   \n",
       "6  raven tuditi mena da slovenija in francija jes...    0    0    1   \n",
       "7  stelzero jesti že sin france rosti stelzero že...    0    0    1   \n",
       "8  analiza dnk roda naj biti jesti domneven sin r...    0    0    1   \n",
       "9      on oddati v p poročanje soden medicina v n pa    1    0    0   \n",
       "\n",
       "   sentiment  neutral  positive  \n",
       "0          3        1        -1  \n",
       "1          3        1        -1  \n",
       "2          3        1        -1  \n",
       "3          3        1        -1  \n",
       "4          3        1        -1  \n",
       "5          4        0         1  \n",
       "6          4        0         1  \n",
       "7          3        1        -1  \n",
       "8          3        1        -1  \n",
       "9          3        1        -1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'senticoref_cleaned.tsv'\n",
    "df.to_csv(name, index=False)\n",
    "#is the data saved ok\n",
    "aa = pd.read_csv(name)\n",
    "aa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
