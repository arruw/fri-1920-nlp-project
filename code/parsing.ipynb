{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to SentiCoref dataset\n",
    "folder = \"../data/SentiCoref_1.0\"\n",
    "files = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets all unique entity numbers within a document\n",
    "def get_entity_count(df):\n",
    "    #only extract entities which have sentiment\n",
    "    entities = [(int) (s) for s in re.findall(r'\\d+', \"\".join(df.number.unique()))]\n",
    "    return sorted(set(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a dictionary of entities\n",
    "def build_initial_dict(df):\n",
    "    #{key: ([tokens], entity_type, sentiment, occurrence)}\n",
    "    d = dict((key, [[], \"_\", 0, 0]) for key in get_entity_count(df))\n",
    "    \n",
    "    for index, row in df[df.number != \"_\"].iterrows():\n",
    "        #entity numbers, can be a single one or a few\n",
    "        numbers = [(int) (s) for s in re.findall(r'\\d+', row.number)]\n",
    "        #token index of the word in document\n",
    "        token_index = ((int) (row.token.split(\"-\")[1])) - 1\n",
    "        for i in range(len(numbers)):\n",
    "            key = numbers[i]\n",
    "\n",
    "            #append token index\n",
    "            d[key][0].append(token_index)\n",
    "\n",
    "            #append entity type\n",
    "            if len(numbers) > 1 and len(row.entity.split(\"|\")) > 1:\n",
    "                if i > len(row.entity.split(\"|\"))-1:\n",
    "                    continue\n",
    "                else:\n",
    "                    types = row.entity.split(\"|\")\n",
    "                    d[key][1] = types[i][:3]\n",
    "            else:\n",
    "                if row.entity != \"_\":\n",
    "                    d[key][1] = row.entity[:3]\n",
    "\n",
    "            #append sentiment\n",
    "            if len(numbers) > 1 and len(row.sentiment.split(\"|\")) > 1:\n",
    "                if i > len(row.sentiment.split(\"|\"))-1:\n",
    "                    continue\n",
    "                else:\n",
    "                    sentiments = row.sentiment.split(\"|\")\n",
    "                    d[key][2] = (int) (sentiments[i][:1])\n",
    "            else:\n",
    "                if row.sentiment != \"_\":\n",
    "                    d[key][2] = (int) (row.sentiment[:1])\n",
    "\n",
    "            #append occurrence\n",
    "            if len(numbers) > 1 and len(row.occurrence.split(\"|\")) > 1:\n",
    "                occurrences = row.occurrence.split(\"|\")\n",
    "                d[key][3] = (int) (occurrences[i].split(\"-\")[-1])\n",
    "            else:\n",
    "                if row.sentiment != \"_\":\n",
    "                    d[key][3] = (int) (row.occurrence.split(\"-\")[-1])\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a dataframe with features from a single document\n",
    "def create_dataframe_from_dict(d, file_number):\n",
    "    keys = list(d.keys())\n",
    "    doc = [file_number for i in range(len(keys))]\n",
    "    tokens = [d[key][0] for key in keys]\n",
    "    types = [d[key][1] for key in keys]\n",
    "    occurrences = [d[key][3] for key in keys]\n",
    "    sentiments = [d[key][2] for key in keys]\n",
    "    \n",
    "    return pd.DataFrame([doc, keys, tokens, types, occurrences, sentiments],\n",
    "                        index=[\"Document\", \"Entity\", \"Tokens\", \"Type\", \"Occurrence\", \"Sentiment\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESSING SENTICOREF DATA\n",
    "entity_df = pd.DataFrame(columns=[\"Document\", \"Entity\", \"Tokens\", \"Type\", \"Occurrence\", \"Sentiment\"])\n",
    "file_numbers = []\n",
    "file_texts = []\n",
    "\n",
    "for file in files:\n",
    "   \n",
    "    #read document, skip header, fill a data frame\n",
    "    document = pd.read_csv(folder + \"/\" + file, \n",
    "                     sep=\"\\t\", \n",
    "                     skiprows=7,\n",
    "                     header=None, \n",
    "                     names=[\"token\", \"char\", \"word\", \"entity\", \"sentiment\", \"occurrence\", \"number\", \"NaN\"], \n",
    "                     quoting=3, \n",
    "                     encoding=\"utf-8\")\n",
    "    \n",
    "    #save file number and text\n",
    "    file_number = (int) (file.split(\".\")[0])\n",
    "    file_numbers.append(file_number)\n",
    "    file_texts.append(list(document.word))\n",
    "    \n",
    "    #create a dataframe from a document and append it to the corpus dataframe\n",
    "    d = build_initial_dict(document)\n",
    "    df = create_dataframe_from_dict(d, file_number)\n",
    "    entity_df = entity_df.append(df)\n",
    "\n",
    "#reset index and save dataframe to pickle    \n",
    "entity_df.reset_index(drop=True, inplace=True)\n",
    "entity_df.to_pickle(\"../data/entities.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Type</th>\n",
       "      <th>Occurrence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[11, 12, 13, 15, 51, 52, 53, 54, 55, 57, 228, ...</td>\n",
       "      <td>PER</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[49]</td>\n",
       "      <td>LOC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[68, 301, 312, 322, 384, 428]</td>\n",
       "      <td>ORG</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[98, 105, 186, 429]</td>\n",
       "      <td>LOC</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[70, 303, 310, 382, 436]</td>\n",
       "      <td>ORG</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14567</td>\n",
       "      <td>9966</td>\n",
       "      <td>25</td>\n",
       "      <td>[355]</td>\n",
       "      <td>LOC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14568</td>\n",
       "      <td>9966</td>\n",
       "      <td>26</td>\n",
       "      <td>[390]</td>\n",
       "      <td>LOC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14569</td>\n",
       "      <td>9966</td>\n",
       "      <td>27</td>\n",
       "      <td>[405]</td>\n",
       "      <td>LOC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14570</td>\n",
       "      <td>9966</td>\n",
       "      <td>28</td>\n",
       "      <td>[411]</td>\n",
       "      <td>LOC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14571</td>\n",
       "      <td>9966</td>\n",
       "      <td>29</td>\n",
       "      <td>[409]</td>\n",
       "      <td>LOC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Document Entity                                             Tokens Type  \\\n",
       "0            1      1  [11, 12, 13, 15, 51, 52, 53, 54, 55, 57, 228, ...  PER   \n",
       "1            1      2                                               [49]  LOC   \n",
       "2            1      3                      [68, 301, 312, 322, 384, 428]  ORG   \n",
       "3            1      4                                [98, 105, 186, 429]  LOC   \n",
       "4            1      5                           [70, 303, 310, 382, 436]  ORG   \n",
       "...        ...    ...                                                ...  ...   \n",
       "14567     9966     25                                              [355]  LOC   \n",
       "14568     9966     26                                              [390]  LOC   \n",
       "14569     9966     27                                              [405]  LOC   \n",
       "14570     9966     28                                              [411]  LOC   \n",
       "14571     9966     29                                              [409]  LOC   \n",
       "\n",
       "      Occurrence Sentiment  \n",
       "0             11         4  \n",
       "1              1         3  \n",
       "2              6         3  \n",
       "3              4         3  \n",
       "4              5         3  \n",
       "...          ...       ...  \n",
       "14567          1         3  \n",
       "14568          1         3  \n",
       "14569          1         3  \n",
       "14570          1         3  \n",
       "14571          1         3  \n",
       "\n",
       "[14572 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unpickled_df = pd.read_pickle(\"../data/entities.pkl\")\n",
    "#unpickled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESSING SENTINEWS DATA\n",
    "#load sentinews document level text\n",
    "sentinews_df = pd.read_csv(\"../data/SentiNews_document-level.txt\", sep=\"\\t\")\n",
    "#use only documents used in senticoref\n",
    "sentinews_df = sentinews_df[sentinews_df['nid'].isin(file_numbers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of documents with sentinews data\n",
    "ids = list(sentinews_df.nid)\n",
    "sources = [url.split(\".\")[1] for url in sentinews_df.main_url]\n",
    "lengths = [len(text) for text in sentinews_df.content]\n",
    "years = [date.split(\"-\")[0] for date in sentinews_df.date]\n",
    "avg_sentiments = [avg for avg in sentinews_df.avg_sentiment]\n",
    "sd_sentiments = [sd for sd in sentinews_df.sd_sentiment]\n",
    "sentiments = [sent for sent in sentinews_df.sentiment]\n",
    "texts = [x for _,x in sorted(zip(file_numbers,file_texts))]\n",
    "\n",
    "document_df = pd.DataFrame([ids, texts, lengths, sources, avg_sentiments, sd_sentiments, sentiments],\n",
    "                        index=[\"Document\", \"Text\", \"Length\", \"Source\", \"Avg_sentiment\", \"Sd_sentiment\", \"Sentiment\"]).T\n",
    "document_df.to_pickle(\"../data/documents.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Source</th>\n",
       "      <th>Avg_sentiment</th>\n",
       "      <th>Sd_sentiment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Evropska, komisija, mora, narediti, analizo, ...</td>\n",
       "      <td>2939</td>\n",
       "      <td>24ur</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.707</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>[Pojavljajo, se, namigi, ,, da, naj, bi, Deuts...</td>\n",
       "      <td>2191</td>\n",
       "      <td>24ur</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>[Predstavniki, ruskega, plinskega, giganta, Ga...</td>\n",
       "      <td>2149</td>\n",
       "      <td>24ur</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.707</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>[Slovenija, ima, z, 3,6, -, odstotno, stopnjo,...</td>\n",
       "      <td>1977</td>\n",
       "      <td>24ur</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.707</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>[Nadzorniki, Darsa, so, razpravljali, o, izgra...</td>\n",
       "      <td>3026</td>\n",
       "      <td>24ur</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.707</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>832</td>\n",
       "      <td>10323</td>\n",
       "      <td>[Čeprav, je, Gašpar, Gašpar, Mišič, član, PS, ...</td>\n",
       "      <td>3005</td>\n",
       "      <td>zurnal24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>833</td>\n",
       "      <td>10369</td>\n",
       "      <td>[SD, največ, podpore, ,, sledi, SDS, ., Desus,...</td>\n",
       "      <td>2304</td>\n",
       "      <td>zurnal24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>834</td>\n",
       "      <td>10395</td>\n",
       "      <td>[Direktor, ZD, Velenje, Jože, Zupančič, je, za...</td>\n",
       "      <td>3381</td>\n",
       "      <td>zurnal24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835</td>\n",
       "      <td>10405</td>\n",
       "      <td>[To, je, razlog, za, pesimizem, pa, tudi, spod...</td>\n",
       "      <td>2285</td>\n",
       "      <td>zurnal24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>836</td>\n",
       "      <td>10426</td>\n",
       "      <td>[Promet, na, dolenjski, avtocesti, po, tem, ,,...</td>\n",
       "      <td>1234</td>\n",
       "      <td>zurnal24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document                                               Text Length  \\\n",
       "0          1  [Evropska, komisija, mora, narediti, analizo, ...   2939   \n",
       "1         20  [Pojavljajo, se, namigi, ,, da, naj, bi, Deuts...   2191   \n",
       "2         32  [Predstavniki, ruskega, plinskega, giganta, Ga...   2149   \n",
       "3         42  [Slovenija, ima, z, 3,6, -, odstotno, stopnjo,...   1977   \n",
       "4         44  [Nadzorniki, Darsa, so, razpravljali, o, izgra...   3026   \n",
       "..       ...                                                ...    ...   \n",
       "832    10323  [Čeprav, je, Gašpar, Gašpar, Mišič, član, PS, ...   3005   \n",
       "833    10369  [SD, največ, podpore, ,, sledi, SDS, ., Desus,...   2304   \n",
       "834    10395  [Direktor, ZD, Velenje, Jože, Zupančič, je, za...   3381   \n",
       "835    10405  [To, je, razlog, za, pesimizem, pa, tudi, spod...   2285   \n",
       "836    10426  [Promet, na, dolenjski, avtocesti, po, tem, ,,...   1234   \n",
       "\n",
       "       Source Avg_sentiment Sd_sentiment Sentiment  \n",
       "0        24ur           3.5        0.707   neutral  \n",
       "1        24ur             3            0   neutral  \n",
       "2        24ur           2.5        0.707   neutral  \n",
       "3        24ur           2.5        0.707   neutral  \n",
       "4        24ur           2.5        0.707   neutral  \n",
       "..        ...           ...          ...       ...  \n",
       "832  zurnal24             3            0   neutral  \n",
       "833  zurnal24             3            0   neutral  \n",
       "834  zurnal24             3            0   neutral  \n",
       "835  zurnal24             3            0   neutral  \n",
       "836  zurnal24             3            0   neutral  \n",
       "\n",
       "[837 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unpickled_df = pd.read_pickle(\"../data/documents.pkl\")\n",
    "#unpickled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
